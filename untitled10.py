# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EAEaR7TRlXvOWyQYccQCm4KShQxRLqyL
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d saroz014/plant-diseases

!unzip plant-diseases.zip

import os
import PIL

count = 0

for folder in os.listdir('/content/dataset_itr2/train'):
  for f in os.listdir(os.path.join('/content/dataset_itr2/train', folder)):
      try :
        img = PIL.Image.open(os.path.join('/content/dataset_itr2/train', folder, f))
      except:
        print(f + ' is Courapted from folder ' + folder)
        os.remove(os.path.join('/content/dataset_itr2/train', folder, f))
        count += 1

count

for folder in os.listdir('/content/dataset_itr2/test'):
  for f in os.listdir(os.path.join('/content/dataset_itr2/test', folder)):
      try :
        img = PIL.Image.open(os.path.join('/content/dataset_itr2/test', folder, f))
      except:
        print(f + ' is Courapted from folder ' + folder)
        os.remove(os.path.join('/content/dataset_itr2/test', folder, f))
        count += 1

count

import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization
test_ds=tf.keras.utils.image_dataset_from_directory(
    directory='/content/dataset_itr2/test',
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=16,
    image_size=(256, 256)
)
train_ds=tf.keras.utils.image_dataset_from_directory(
    directory='/content/dataset_itr2/train',
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=16,
    image_size=(256, 256)
)

def process(image,label):
  image=tf.cast(image/255.0,tf.float32)
  return image,label

test_ds=test_ds.map(process)
train_ds=train_ds.map(process)

sq=Sequential()
sq.add(Conv2D(16,(3,3),activation='relu',input_shape=(256,256,3)))
sq.add(BatchNormalization())
sq.add(MaxPooling2D((2,2)))
sq.add(Conv2D(16,(3,3),activation='relu'))
sq.add(BatchNormalization())
sq.add(MaxPooling2D((2,2)))
sq.add(Conv2D(32,(3,3),activation='relu'))
sq.add(BatchNormalization())
sq.add(MaxPooling2D((2,2)))
sq.add(Conv2D(32,(3,3),activation='relu'))
sq.add(BatchNormalization())
sq.add(MaxPooling2D((2,2)))
sq.add(Conv2D(64,(3,3),activation='relu'))
sq.add(BatchNormalization())
sq.add(MaxPooling2D((2,2)))
sq.add(Conv2D(64,(3,3),activation='relu'))
sq.add(BatchNormalization())
sq.add(MaxPooling2D((2,2)))

sq.add(Flatten())

sq.add(Dense(128,activation='relu'))
sq.add(Dropout(0.2))
sq.add(Dense(38,activation='softmax'))

sq.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

history=sq.fit(train_ds,epochs=20,validation_data=test_ds)